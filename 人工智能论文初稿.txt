


人工智能基础与应用
2025 年课程论文





题    目	基于Keras的手写数字图像识别与模型优化
专业班级	电气2203班
学    号	2022001326
学生姓名	谢晓博
　　　　　　　　




完成日期：2025年5月

基于Keras的手写数字图像识别与模型优化 
　　　摘要：近年来，人工智能技术迅猛发展，深度学习方法在图像识别领域取得了令人瞩目的成就。手写数字识别作为图像分类的一个典型应用，不仅是技术研究的热点，也是实际生活中诸如银行票据处理、邮政自动分拣等场景中的关键环节。多层感知机（MLP）作为神经网络的基础结构，因其实现简单且效果稳定，成为了很多入门和教学项目的首选。本项目以Keras深度学习框架为依托，系统地探索了MLP模型在手写数字识别任务中的应用过程。首先，项目回顾了神经网络的基本理论，包括模型结构、激活函数、优化算法等内容。在数据处理阶段，利用MNIST标准数据集，通过归一化、独热编码等预处理手段，为后续的建模和训练打下良好基础。模型搭建方面，详细尝试了不同激活函数和优化器的组合，并通过引入L2正则化和Dropout技术，有效防止了模型过拟合。实验中，通过对比各类参数设置，发现ReLU激活函数和Adam优化器的组合表现最为优异，模型在测试集上的准确率稳定达到97%以上。此外，项目还通过可视化混淆矩阵和典型误分类样本，深入分析了模型在易混淆数字上的表现，发现数字形态相似或书写模糊时容易出错。针对这些问题，提出了如引入卷积神经网络、数据增强等改进方向。整体来看，本项目不仅实现了对手写数字的高效识别，也为人工智能课程实践和相关领域的深入研究提供了有益的参考和借鉴。
关键词：手写数字识别；深度学习；Keras；MNIST
Keras-Based Handwritten Digit Image Recognition and Model Optimization
　　　Abstract: In recent years, artificial intelligence has developed at a remarkable pace, and deep learning methods have achieved impressive results in the field of image recognition. Handwritten digit recognition, as a classic application of image classification, is not only a hot topic in technical research but also plays a vital role in practical scenarios such as bank check processing and automated postal sorting. The multilayer perceptron (MLP), as a fundamental neural network structure, is widely favored for its simplicity and stable performance, making it a popular choice for entry-level projects and educational purposes. This project systematically explores the application of the MLP model to handwritten digit recognition tasks, using the Keras deep learning framework.At the outset, the project reviews the basic theories behind neural networks, including model architecture, activation functions, and optimization algorithms. For data processing, the MNIST standard dataset is utilized, with preprocessing steps such as normalization and one-hot encoding ensuring the data is well-prepared for model training. During model construction, different combinations of activation functions and optimizers are tested, and techniques like L2 regularization and Dropout are introduced to effectively prevent overfitting. Experimental comparisons indicate that the combination of the ReLU activation function and Adam optimizer consistently delivers the best performance, with the model achieving stable test accuracy above 97%.Moreover, by visualizing confusion matrices and typical misclassified samples, the project provides an in-depth analysis of the model's performance on easily confused digits, revealing that errors often occur when digits have similar shapes or ambiguous handwriting. Based on these findings, the report suggests potential improvements such as incorporating convolutional neural networks (CNNs) and applying data augmentation strategies. Overall, this project not only achieves efficient recognition of handwritten digits but also offers valuable insights and references for artificial intelligence course projects and further research in related fields.
Keywords：Handwritten digit recognition; Deep learning; Keras; MNIST

1. 概述
近年来，人工智能的不断发展推动了各行各业的技术进步，尤其是深度学习的兴起极大地拓展了机器在图像识别、语音处理和自然语言理解等领域的应用边界。在图像识别领域，手写数字识别因其问题定义明确、数据集标准、评估方法统一，不仅成为了学术界检验神经网络算法有效性的经典课题，也广泛应用于金融票据处理、邮政分拣、智能终端输入等实际场景。自20世纪90年代LeCun等人提出基于神经网络的手写数字识别系统以来，随着神经网络结构的不断演化和优化算法的持续进步，该领域的研究成果不断丰富，极大地推动了模式识别与自动化文档处理技术的进步[1][2]。
手写数字识别的研究不仅具有显著的理论价值，还在实际应用中展现出强大的生命力。随着社会对自动化和智能化的需求日益提升，提升识别系统的准确性和泛化能力已成为技术发展的重要方向。高效、稳定的手写数字识别技术能够极大地提升信息处理效率，降低人工成本，对于银行票据自动识别、邮政信件分拣、智能设备手写输入等多个领域具有不可替代的作用。同时，该任务由于其实现门槛适中、理论与实践结合紧密，也成为了高校人工智能课程和实践项目的经典案例，有助于学生全面理解神经网络模型的构建、训练及其参数优化的方法[3][4]。
从国际研究现状来看，主流的研究都采用MNIST等标准手写数字数据集，深入探索多层感知机（MLP）、卷积神经网络（CNN）等多种深度学习模型在识别性能上的表现，通过不断改进激活函数、优化算法和正则化技术，持续提升模型的准确率和泛化能力。国内学者也在模型创新和实际部署方面取得了显著进展，将研究成果应用于金融、教育等领域，推动了智能信息处理技术的产业化进程[3]。
在这样的背景下，基于Keras深度学习框架，结合MNIST手写数字数据集，系统设计并优化手写数字识别模型，不仅能够检验和加深对神经网络相关理论的理解，还能通过对比实验明确不同激活函数、优化器、正则化方法等关键因素对模型性能的实际影响。此外，深入分析模型在误判样本上的表现和成因，不仅有助于发现现有方法的不足，也为后续的改进和创新提供了理论依据。通过本项目的设计与实践，期望为人工智能技术的学习者和相关领域研究者提供理论与方法的参考，同时为实际应用开发提供有益的借鉴。
2. 技术原理
手写数字识别任务背后涉及的技术基础主要集中在人工神经网络、激活函数、优化算法、正则化方法以及深度学习框架的选型等方面。理解这些理论不仅有助于模型的合理设计和优化，也为后续的实验分析和结果解释提供了坚实的基础。
人工神经网络最初受生物神经系统的启发，通过大量“神经元”节点之间的连接和信息传递，实现对复杂数据模式的学习和识别。最基础的多层感知机（MLP）结构由输入层、若干隐藏层和输出层组成，每一层的神经元与相邻层全连接，能够通过权重参数的调整完成高维空间的非线性映射。在实际应用中，MLP通过前向传播获得输出预测结果，再通过反向传播算法根据损失函数对输出误差进行反馈调整，逐步优化网络参数[5][6]。这种训练方式极大提升了神经网络在分类和回归任务中的表现力。
激活函数的选择是神经网络设计中的关键环节。它赋予网络以非线性能力，使其能够拟合复杂的数据分布。早期网络多采用Sigmoid和Tanh等激活函数，但这类函数在深层网络中容易出现梯度消失，影响训练效率。近年来，ReLU（Rectified Linear Unit）因其简单高效、能够缓解梯度消失问题而被广泛采用，成为深度学习主流激活方式[7]。当然，实际应用中还会根据具体任务尝试不同激活函数的组合，以获得更优的性能。
优化算法负责在训练过程中不断调整网络权重，使损失函数逐步收敛。经典的随机梯度下降法（SGD）以其实现简单和资源消耗低而被广泛使用，但在噪声较多或损失函数地形复杂时容易陷入局部最优。为提升训练效率，Adam等自适应优化算法被提出，结合了动量和自适应学习率优势，能够更快、更稳定地收敛到较优解，因此在深度学习实际应用中获得了极高的普及[8]。优化算法的选型和参数调节直接决定了模型训练的速度和最终效果。
随着模型复杂度的提升，神经网络极易在训练集上表现优异，却在新数据上出现性能下降，即过拟合现象。为此，正则化方法成为提升泛化能力的重要工具。L2正则化通过限制权重的绝对值，防止模型过度依赖个别参数，从而增强网络稳健性。Dropout则通过在训练过程中随机“屏蔽”部分神经元，打破神经元间的依赖关系，有效降低了过拟合风险[9]。这些方法相互配合，使得神经网络在实际应用中更加可靠。
在实际工程实现中，Keras作为高级深度学习框架，以其简洁的API和良好的兼容性成为了学术和工业界的重要工具。Keras不仅支持快速搭建复杂的神经网络结构，还与TensorFlow等主流底层计算框架无缝对接，大大降低了模型开发和部署的门槛[10]。通过灵活的模块化设计，研究者和开发者可以方便地实现各类实验组合，快速迭代模型方案。
数据集是支撑模型训练和评测的基础。MNIST数据集自发布以来成为手写数字识别领域的标准数据集，包含大量风格多样的手写数字图片，且样本已预先标注。其规范的数据格式和广泛的应用基础，为不同算法和模型的横向对比提供了可靠平台[11]。基于MNIST的实验不仅可以集中测试网络结构和训练策略的改进效果，也为后续推广到更复杂的实际场景打下了基础。
综上所述，手写数字识别项目背后的核心技术原理涵盖了神经网络结构、激活函数、优化算法、正则化技术、深度学习框架与标准数据集等多个方面。这些理论的不断发展和完善，为模型的高效训练与广泛应用提供了有力保障。
3. 项目实现过程
3.1 环境配置与依赖安装
在本项目中，模型的开发与实验均基于Python语言及其深度学习生态完成。主要依赖包括TensorFlow（集成Keras接口）、NumPy、Matplotlib。开发环境为Anaconda或Miniconda，便于依赖包的统一管理。
依赖安装命令：
pip install tensorflow matplotlib numpy
3.2 数据集加载与预处理
本项目采用MNIST手写数字数据集。数据使用Keras内置接口直接下载并加载，包含60000张训练图片和10000张测试图片。每张图片为28×28像素的灰度图像，像素值范围为0-255。
数据预处理步骤包括：
- 图像拉平成一维向量，便于输入到全连接神经网络；
- 像素归一化处理，将数据缩放到[0,1]区间；
- 标签进行独热编码（one-hot encoding），适配多分类输出。

**数据预处理代码：**
```python
import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

# 加载数据
(X_train, y_train), (X_test, y_test) = mnist.load_data()
# 拉平并归一化
X_train = X_train.reshape(-1, 28*28).astype('float32') / 255.0
X_test = X_test.reshape(-1, 28*28).astype('float32') / 255.0
# 标签独热编码
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)
```

插图1  2

3.3 网络结构设计与模型搭建
本项目以多层感知机（MLP）为基础结构，设计包含一个输入层、一个隐藏层和一个输出层的神经网络。输入层节点数为784，对应28×28像素；隐藏层选用128个神经元，激活函数采用ReLU；输出层为10个节点，激活函数为softmax，实现对0-9数字的多分类。
模型搭建与编译代码：
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(128, activation='relu', input_shape=(784,)),
    Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```
插图3：此处插入“多层感知机（MLP）网络结构示意图”（见图3）

3.4 模型训练与评估
模型训练过程中，设置训练轮数（如10轮）、批量大小（如128），并划分部分训练集作为验证集。模型训练期间记录损失和准确率曲线，方便后续分析。
模型训练与测试代码：
```python
import matplotlib.pyplot as plt

history = model.fit(X_train, y_train_cat, epochs=10, batch_size=128, validation_split=0.1, verbose=2)
test_loss, test_acc = model.evaluate(X_test, y_test_cat)
print(f"测试集准确率：{test_acc:.4f}")

# 可视化训练与验证准确率
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('训练与验证准确率变化')
plt.show()
```
插图4：此处插入“模型训练过程中训练集与验证集准确率变化曲线”（见图4）。

3.5 误分类样本可视化

为进一步分析模型的误判情况，通过对比模型预测标签与真实标签，筛选部分错误分类样本，进行图像展示和标签对比。通过可视化，可以直观了解模型在特定数字上的混淆情况，为后续优化提供依据。

**误分类样本展示代码：**
```python
y_pred = model.predict(X_test).argmax(axis=1)
err_idx = np.where(y_pred != y_test)[0][:10]
plt.figure(figsize=(10,2))
for i, idx in enumerate(err_idx):
    plt.subplot(1,10,i+1)
    plt.imshow(X_test[idx].reshape(28,28), cmap='gray')
    plt.title(f"T:{y_test[idx]},P:{y_pred[idx]}")
    plt.axis('off')
plt.show()
```
插图5：此处插入“测试集中部分被误分类的手写数字样本及其标签”（见图5）。

3.6 参数与结构优化
为提升模型性能，进一步尝试不同激活函数（如sigmoid、tanh）、优化器（如SGD）、正则化方法（如Dropout、L2正则化）等参数组合。每组实验均记录测试集准确率，并绘制对比柱状图，分析各参数对模型表现的影响。
激活函数与优化器对比代码框架：
```python
from tensorflow.keras.layers import Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import SGD

# 激活函数对比
activations = ['relu', 'sigmoid', 'tanh']
results = {}
for act in activations:
    mdl = Sequential([
        Dense(128, activation=act, input_shape=(784,)),
        Dense(10, activation='softmax')
    ])
    mdl.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    mdl.fit(X_train, y_train_cat, epochs=5, batch_size=128, verbose=0)
    acc = mdl.evaluate(X_test, y_test_cat, verbose=0)[1]
    results[act] = acc
plt.bar(results.keys(), results.values())
plt.xlabel('Activation Function')
plt.ylabel('Test Accuracy')
plt.title('不同激活函数的测试集准确率')
plt.show()
插图6：此处插入“不同激活函数下模型在测试集上的准确率对比”（见图6）。

# Dropout与L2正则化实验
model_reg = Sequential([
    Dense(128, activation='relu', input_shape=(784,), kernel_regularizer=l2(0.01)),
    Dropout(0.5),
    Dense(10, activation='softmax')
])
model_reg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history_reg = model_reg.fit(X_train, y_train_cat, epochs=10, batch_size=128, validation_split=0.1, verbose=2)
acc_reg = model_reg.evaluate(X_test, y_test_cat, verbose=0)[1]
plt.plot(history_reg.history['accuracy'], label='Train')
plt.plot(history_reg.history['val_accuracy'], label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('正则化+Dropout训练与验证准确率')
plt.show()
```
插图7：此处插入“加入正则化与Dropout后模型训练及验证准确率变化曲线”（见图7）。

4. 实验结果与分析
本部分围绕基于Keras实现的多层感知机（MLP）神经网络在MNIST手写数字识别任务中的实验过程与主要结果展开细致分析。通过一系列实验，我们不仅考察了基础模型的性能表现，也从参数优化、误分类现象、正则化效果和模型局限性等多个角度，对深度学习方法在图像识别领域的应用能力进行了系统梳理。
在实验初期，我们采用了单隐藏层、128个神经元、ReLU激活函数和Adam优化器的MLP作为基准模型。数据经归一化和独热编码处理后，模型在10轮训练后便能迅速收敛，训练集与验证集的准确率曲线高度一致，几乎没有出现过拟合现象。最终，该模型在MNIST测试集上的准确率稳定在97%以上。值得一提的是，即使在结构和参数都较为基础的情况下，神经网络依然展现出对手写数字识别任务的强大建模能力，这也反映了深度学习方法在标准化视觉任务中的天然优势。
在进一步的参数对比实验中，我们针对激活函数、优化算法和模型结构进行了系统性测试。结果表明，ReLU激活函数无论在收敛速度还是最终准确率上都优于Sigmoid和Tanh，这与其在缓解梯度消失、提升训练效率方面的理论优势高度吻合。Adam优化器凭借自适应学习率和动量机制，在训练初期即可表现出更快的收敛速度和更高的稳定性，为模型在有限轮数内达到最佳表现提供了保障。通过对比不同参数配置下的训练损失和准确率曲线，可以清晰看出模型训练效率和泛化能力的显著差异。
随着实验深入，我们还尝试了增加隐藏层数量、调整神经元规模等结构扩展方式。实验发现，模型复杂度提升到一定程度后准确率提升趋于饱和，甚至会因参数过多导致过拟合风险增加。为此，在模型中引入了L2正则化和Dropout技术。L2正则化通过惩罚权重过大防止模型过拟合，Dropout则在训练过程中随机舍弃部分神经元，有效增强了模型的鲁棒性。实验结果显示，正则化和Dropout的引入使验证集准确率表现更加平稳，训练集与验证集准确率的差距明显缩小，模型的泛化能力得到提升。
在模型性能达到较高水平后，我们对误分类样本进行了可视化分析。通过混淆矩阵和部分错误样本的展示，发现大多数误判集中在形态相近、书写模糊或轮廓不清晰的数字对之间，如3和5、4和9等。这些错误主要源于样本主观书写风格差异和数据本身的复杂性，并不完全是模型结构或训练不足所致。针对这些现象，未来可通过卷积神经网络等结构引入空间特征提取能力，或采用数据增强扩展训练样本的多样性，以进一步降低误判率。
此外，我们还尝试了数据增强等扩展策略，诸如对训练图片进行旋转、平移和缩放等操作，从而提升模型对变体数字的适应能力，进一步提升了模型在特殊书写样本上的表现。经过这些实验证明，模型性能的持续提升不仅依赖于结构优化，更需要多维度的训练策略和数据处理手段协同作用。
通过本部分的实验与分析，不仅验证了深度学习方法在手写数字识别中的有效性，也为模型进一步优化和实际应用提供了实践经验和理论参考。合理的结构设计、科学的参数设置、有效的正则化和数据增强，都是提升模型表现和泛化能力的核心要素。未来，结合卷积神经网络、迁移学习等前沿技术，有望持续突破模型在更复杂场景下的识别能力与适应性，推动深度学习方法在实际图像识别任务中的进一步落地。
````markdown name=5_conclusion.md
# 5. 总结与展望
本研究以Keras为平台，围绕MNIST手写数字识别任务，深入探讨了多层感知机（MLP）神经网络的结构设计、训练过程、参数优化和泛化能力提升等关键环节。整个实验过程涵盖了数据预处理、模型搭建、训练与评估、正则化和误分类分析等多个方面，形成了一套较为完整的神经网络在图像分类应用中的实践范例。
从实验结果来看，基础MLP模型经过标准化的数据预处理和合理的参数配置后，在MNIST测试集上能够取得97%以上的准确率，表现出深度学习方法在标准化视觉识别任务上的高效性和实用性。通过对激活函数和优化算法的对比发现，ReLU激活函数和Adam优化器的组合能够有效提升模型的收敛速度和最终性能。正则化方法的引入，尤其是L2正则化和Dropout，不仅在一定程度上抑制了过拟合，还使训练集和验证集的准确率表现更加平稳，模型在新样本上的预测能力也得到了显著提升。这些实验结果充分说明，科学的模型结构设计和系统的参数优化是实现高效神经网络学习的基础[16]。
然而，尽管基础模型已能取得较高的准确率，实验也暴露出其在应对复杂、模糊、风格多样的手写数字样本时的不足。混淆矩阵和误分类样本分析显示，模型在区分形态相近或书写不规范的数字时仍会出现一定程度的误判，这部分归因于简单结构对空间特征的提取能力有限。特别是在面对更高噪声、更复杂背景或多样化输入的实际应用环境时，MLP结构的局限性会更加明显。为此，未来的研究可以从几个方向进一步拓展：首先，卷积神经网络（CNN）等结构因其在图像空间特征提取上的独特优势，已成为应对复杂视觉任务的主流方案。其次，数据增强、迁移学习等策略能够提升模型在不同书写风格、噪声扰动下的适应能力。最后，集成学习方法通过融合多种模型的预测结果，有望进一步提高系统整体的鲁棒性和泛化能力[17]。
值得关注的是，随着人工智能技术的不断发展，神经网络模型的部署效率、推理速度和资源消耗也逐渐成为实际应用中的重要考量。如何兼顾模型的识别准确率与轻量化部署，推动深度学习技术在移动端、嵌入式等资源受限场景的落地，将成为后续研究和工程实现的重要方向。此外，持续跟踪和分析模型的误分类样本，可以为数据采集、标注和算法优化提供有益反馈，推动手写数字识别系统向更高水平演进。
综上所述，基于Keras的多层感知机手写数字识别模型通过系统性实验与分析，不仅实现了对标准任务的高效解决，也为神经网络在图像识别领域的进一步优化和实际应用提供了理论基础和实践经验。未来结合更复杂的模型结构、更丰富的数据资源和更智能的训练策略，手写数字识别等模式识别技术将在更多实际场景中展现出更广阔的应用前景[18]。


参考文献

[1] LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.
[2] LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.
[3] 王亮, 李明, 刘杰. (2022). 基于深度学习的票据识别系统设计. 计算机系统应用, 31(6): 68-74.
[4] 张伟, 赵鹏, 李思远. (2021). Keras深度学习框架在人工智能教学中的应用. 现代远距离教育, 39(4): 49-56.
[5] Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.
[6] Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533-536.
[7] Nair, V., & Hinton, G. E. (2010). Rectified linear units improve restricted Boltzmann machines. In ICML.
[8] Kingma, D. P., & Ba, J. L. (2015). Adam: A method for stochastic optimization. ICLR.
[9] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1), 1929-1958.
[10] Chollet, F., & others. (2015). Keras: Deep learning for humans. https://keras.io
[11] LeCun, Y., Cortes, C., & Burges, C. J. (2010). MNIST handwritten digit database. AT&T Labs [Online].
[12] Abadi, M., Barham, P., Chen, J., et al. (2016). TensorFlow: A system for large-scale machine learning. OSDI, 16, 265-283.
[13] Deng, L. (2012). The MNIST database of handwritten digit images for machine learning research. IEEE Signal Processing Magazine, 29(6), 141-142.
[14] 王斌, 刘莹, 陈晓. (2023). 基于Keras的深度学习实验教学平台设计与实现. 计算机应用研究, 40(4): 1131-1136.
[15] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1), 1929-1958.
[16] LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.
[17] Zhou, Z. H. (2012). Ensemble methods: foundations and algorithms. Chapman and Hall/CRC.
[18] Simonyan, K., & Zisserman, A. (2015). Very deep convolutional networks for large-scale image recognition. In ICLR.